{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine set experiment\n",
      "Corss Validation Accurancy is  0.7458333333333333\n",
      "LDA accurancy 0.7044025157232704\n",
      "The confusion matrix is\n",
      " [[62 27]\n",
      " [20 50]]\n",
      "Recall 0.7560975609756098\n",
      "Precision 0.6966292134831461\n",
      "-----------------\n",
      "\n",
      "Study Rate at 1e-06\n",
      "Corss Validation Accurancy is  0.6298611111111111\n",
      "Logistic Accurancy: 0.610062893081761\n",
      "Study Rate at 1e-05\n",
      "Corss Validation Accurancy is  0.5569444444444444\n",
      "Logistic Accurancy: 0.5849056603773585\n",
      "Study Rate at 0.0001\n",
      "Corss Validation Accurancy is  0.5625\n",
      "Logistic Accurancy: 0.5849056603773585\n",
      "Study Rate at 0.001\n",
      "Corss Validation Accurancy is  0.5166666666666667\n",
      "Logistic Accurancy: 0.5660377358490566\n",
      "\n",
      "Cancer set experiment\n",
      "Corss Validation Accurancy is  0.9642276422764228\n",
      "LDA accurancy 0.9264705882352942\n",
      "The confusion matrix is\n",
      " [[47  1]\n",
      " [ 4 16]]\n",
      "Recall 0.9215686274509803\n",
      "Precision 0.9791666666666666\n",
      "-----------------\n",
      "\n",
      "Study Rate at 1e-06\n",
      "Corss Validation Accurancy is  0.3463414634146342\n",
      "Linear Model Accurancy: 0.38235294117647056\n",
      "The confusion matrix is\n",
      " [[ 0 42]\n",
      " [ 0 26]]\n",
      "Recall nan\n",
      "Precision 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongdong/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:63: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study Rate at 1e-05\n",
      "Corss Validation Accurancy is  0.8634146341463413\n",
      "Linear Model Accurancy: 0.8529411764705882\n",
      "The confusion matrix is\n",
      " [[36  6]\n",
      " [ 4 22]]\n",
      "Recall 0.9\n",
      "Precision 0.8571428571428571\n",
      "Study Rate at 0.0001\n",
      "Corss Validation Accurancy is  0.9235772357723577\n",
      "Linear Model Accurancy: 0.8970588235294118\n",
      "The confusion matrix is\n",
      " [[39  3]\n",
      " [ 4 22]]\n",
      "Recall 0.9069767441860465\n",
      "Precision 0.9285714285714286\n",
      "Study Rate at 0.001\n",
      "Corss Validation Accurancy is  0.9398373983739837\n",
      "Linear Model Accurancy: 0.9264705882352942\n",
      "The confusion matrix is\n",
      " [[41  1]\n",
      " [ 4 22]]\n",
      "Recall 0.9111111111111111\n",
      "Precision 0.9761904761904762\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from statistics import mean\n",
    "# one can add the limit number of iterations\n",
    "class logistic_reg:\n",
    "    def __init__(self ,x_train,y_train, x_test,y_test,parameter):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.w = parameter\n",
    "\n",
    "    def fit(self,iteration, studyRate, use_reg):\n",
    "        for it in range(iteration):\n",
    "            self.update(studyRate,use_reg)\n",
    "        return self.w\n",
    "\n",
    "    def update(self,studyRate,use_reg):\n",
    "        prediction = 0\n",
    "        for i in range(self.x_train.shape[0]):\n",
    "            x_i = self.x_train[i].T\n",
    "            prediction += x_i.dot(self.y_train[i]- expit(self.w.T.dot(x_i)))\n",
    "        if use_reg[0]:\n",
    "            lmd = use_reg[1]\n",
    "            m = self.x_train.shape[1]\n",
    "            #updata every theta except the w0\n",
    "            w = self.w\n",
    "            w[0] = 0\n",
    "            prediction += (2*lmd)*w\n",
    "            # aka L2-regularization\n",
    "        modifying_number = studyRate * prediction\n",
    "        self.w = self.w + modifying_number\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_per =expit(X.dot(self.w))\n",
    "        y_hat = np.where(y_per > 0.5, 1, 0)\n",
    "        return y_hat\n",
    "\n",
    "    def evaluate_acc(self):\n",
    "        predicted_classes = self.predict(self.x_test)\n",
    "        predicted_classes = predicted_classes.flatten()\n",
    "        n = len(predicted_classes)\n",
    "        count = 0\n",
    "        for i in range(n):\n",
    "            if predicted_classes[i] == self.y_test[i]:\n",
    "                count +=1\n",
    "        accuracy = float(count)/n\n",
    "        return accuracy\n",
    "\n",
    "    def confusion_matrix(self):\n",
    "        cm = confusion_matrix(self.y_test, self.predict(self.x_test))\n",
    "        print(\"The confusion matrix is\\n\",cm)\n",
    "        ture_positive =cm[0,0]\n",
    "        ture_negative =cm[1,1]\n",
    "        false_positive =cm[0,1]\n",
    "        false_negative =cm[1,0]\n",
    "        print(\"Recall\", ture_positive/(ture_positive+false_negative))\n",
    "        print(\"Precision\",ture_positive/(ture_positive+false_positive))\n",
    "\n",
    "    def validationSets(self,fold_num):\n",
    "        n = len(self.x_train)\n",
    "        fsize = int(n/fold_num)\n",
    "        remain=n%fold_num\n",
    "        folds_x=[]\n",
    "        folds_y=[]\n",
    "        start=0\n",
    "        for k in range(fold_num):\n",
    "            if k < remain:\n",
    "                end=start+fsize+1\n",
    "                folds_x.append(self.x_train[start:end])\n",
    "                folds_y.append(self.y_train[start:end])\n",
    "                start=end\n",
    "            else:\n",
    "                end=start+fsize\n",
    "                folds_x.append(self.x_train[start:end])\n",
    "                folds_y.append(self.y_train[start:end])\n",
    "                start=end\n",
    "        #print(folds_x,folds_y)\n",
    "        return folds_x,folds_y\n",
    "\n",
    "    def crossValidation(self,folds_x,folds_y, iter, study_rate, w,use_reg):\n",
    "        # iter=gradient iteration times\n",
    "        accurancy = float(0.0000000)\n",
    "        k = len(folds_x)\n",
    "        for i in range(k):\n",
    "            valid_x = folds_x[i]\n",
    "            valid_x = np.array(valid_x)\n",
    "\n",
    "            valid_y = folds_y[i]\n",
    "            valid_y = np.array(valid_y)\n",
    "\n",
    "            train_x = [folds_x[j] for j in range(k) if j != i]\n",
    "            train_x = np.concatenate(train_x, axis=0)\n",
    "            train_x = np.array(train_x)\n",
    "\n",
    "            train_y = [folds_y[j] for j in range(k) if j != i]\n",
    "            train_y = np.concatenate(train_y, axis=0)\n",
    "            train_y = np.array(train_y)\n",
    "\n",
    "            X = logistic_reg(train_x, train_y, valid_x, valid_y, w)\n",
    "            X.fit(iter, study_rate,use_reg)\n",
    "            accurancy+=X.evaluate_acc()\n",
    "        accurancy = accurancy/ k\n",
    "        print(\"Corss Validation Accurancy is \", accurancy)\n",
    "\n",
    "class lda_model:\n",
    "    def __init__(self):\n",
    "        self.w0 = 0.00000000\n",
    "        self.u0 = 0.00000000\n",
    "        self.u1 = 0.00000000\n",
    "        self.cov = 0.00000000\n",
    "\n",
    "    def fit(self, featuresDataSet, classDataSet):\n",
    "        X = np.copy(featuresDataSet)\n",
    "        Y = np.copy(classDataSet)\n",
    "\n",
    "        p1 = (np.count_nonzero(Y == 1)) / float(len(Y))\n",
    "        p0 = (len(Y) - np.count_nonzero(Y == 1)) / float(len(Y))\n",
    "\n",
    "        X0 = np.zeros(shape=(X.shape[0], X.shape[1]))\n",
    "        X1 = np.zeros(shape=(X.shape[0], X.shape[1]))\n",
    "        m = 0\n",
    "        n = 0\n",
    "        for j in range(len(Y)):\n",
    "            if Y[j] == 0:\n",
    "                X0[m] = X[j]\n",
    "                m = m + 1\n",
    "            else:\n",
    "                X1[n] = X[j]\n",
    "                n = n + 1\n",
    "        self.u0 = X0.mean(0) * (X.shape[0]) / (X.shape[0] - np.count_nonzero(Y == 1))\n",
    "        self.u1 = X1.mean(0) * (X.shape[0]) / (np.count_nonzero(Y == 1))\n",
    "\n",
    "        self.cov = np.zeros(shape=(X.shape[1], X.shape[1]))\n",
    "        for k in range(len(Y)):\n",
    "            if Y[k] == 0:\n",
    "                self.cov = self.cov + (np.matmul(np.transpose([X[k] - self.u0]), [X[k] - self.u0]))\n",
    "            else:\n",
    "                self.cov = self.cov + (np.matmul(np.transpose([X[k] - self.u1]), [X[k] - self.u1]))\n",
    "\n",
    "        self.cov = (self.cov) / (len(Y) - 2)\n",
    "        self.w0 = np.log(p1 / p0) - (1 / 2) * (np.matmul(np.matmul(self.u1, np.linalg.inv(self.cov)), self.u1)) + (1 / 2) * (np.matmul(np.matmul(self.u0, np.linalg.inv(self.cov)), self.u0))\n",
    "\n",
    "    def predictOneExample(self, dataX):\n",
    "        value = self.w0 + np.matmul(np.matmul(dataX, np.linalg.inv(self.cov)), self.u1 - self.u0)\n",
    "        if value > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def predict(self, pX):\n",
    "        values = np.zeros(shape=(pX.shape[0]))\n",
    "        for g in range(pX.shape[0]):\n",
    "            values[g] = self.predictOneExample(pX[g])\n",
    "        return values\n",
    "\n",
    "    def evaluate_acc(self, trueY, eY):\n",
    "        count = 0\n",
    "        index = 0\n",
    "        for g in range(len(eY)):\n",
    "            if eY[g] == trueY[g]:\n",
    "                count = count + 1\n",
    "                index = index + 1\n",
    "            else:\n",
    "                index = index + 1\n",
    "        return count / index\n",
    "\n",
    "    def confusion_matrix(self,x_test,y_test):\n",
    "        cm = confusion_matrix(y_test, self.predict(x_test))\n",
    "        print(\"The confusion matrix is\\n\",cm)\n",
    "        ture_positive =cm[0,0]\n",
    "        ture_negative =cm[1,1]\n",
    "        false_positive =cm[0,1]\n",
    "        false_negative =cm[1,0]\n",
    "        print(\"Recall\", ture_positive/(ture_positive+false_negative))\n",
    "        print(\"Precision\",ture_positive/(ture_positive+false_positive))\n",
    "\n",
    "    def validationSets(self,fold_num,x_train,y_train):\n",
    "        n = len(x_train)\n",
    "        fsize = int(n/fold_num)\n",
    "        remain=n%fold_num\n",
    "        folds_x=[]\n",
    "        folds_y=[]\n",
    "        start=0\n",
    "        for k in range(fold_num):\n",
    "            if k < remain:\n",
    "                end=start+fsize+1\n",
    "                folds_x.append(x_train[start:end])\n",
    "                folds_y.append(y_train[start:end])\n",
    "                start=end\n",
    "            else:\n",
    "                end=start+fsize\n",
    "                folds_x.append(x_train[start:end])\n",
    "                folds_y.append(y_train[start:end])\n",
    "                start=end\n",
    "        return folds_x,folds_y\n",
    "\n",
    "    def crossValidation(self,folds_x,folds_y):\n",
    "        # iter=gradient iteration times\n",
    "        accurancy = float(0.0000000)\n",
    "        k = len(folds_x)\n",
    "        for i in range(k):\n",
    "            valid_x = folds_x[i]\n",
    "            valid_x = np.array(valid_x)\n",
    "\n",
    "            valid_y = folds_y[i]\n",
    "            valid_y = np.array(valid_y)\n",
    "\n",
    "            train_x = [folds_x[j] for j in range(k) if j != i]\n",
    "            train_x = np.concatenate(train_x, axis=0)\n",
    "            train_x = np.array(train_x)\n",
    "\n",
    "            train_y = [folds_y[j] for j in range(k) if j != i]\n",
    "            train_y = np.concatenate(train_y, axis=0)\n",
    "            train_y = np.array(train_y)\n",
    "            lda = lda_model()\n",
    "            lda.fit(train_x, train_y)\n",
    "            accurancy+=lda.evaluate_acc(valid_y,lda.predict(valid_x))\n",
    "        accurancy = accurancy/ k\n",
    "        print(\"Corss Validation Accurancy is \", accurancy)\n",
    "\n",
    "class help_method():\n",
    "    def zeroOrOne(x):\n",
    "        if x > 5:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def train_test_x_y(feature_set,r,y_name):\n",
    "        sp = int(len(feature_set) * r)\n",
    "        train = feature_set[sp:]\n",
    "        test = feature_set[:sp]\n",
    "        return train.drop(y_name,axis=1).to_numpy(), train[y_name].to_numpy(), test.drop(y_name,axis=1).to_numpy(), test[y_name].to_numpy()\n",
    "\n",
    "    def shuffle(data_frame):\n",
    "        return data_frame.sample(frac=1)\n",
    "\n",
    "    def random_parameter_generator(length):\n",
    "        # w = [random.randint(-1, 1)] * length\n",
    "        w = [0] * length\n",
    "        return np.asarray(w)\n",
    "\n",
    "    def dummy_insert(data):\n",
    "        data.insert(0, \"dummy\", 1)\n",
    "\n",
    "    def take_mean(twod_array):\n",
    "        m = len(twod_array[0])\n",
    "        n = len(twod_array)\n",
    "        b=[]\n",
    "        for i in range(n):\n",
    "            b.append((sum(twod_array[i]))/m)\n",
    "        b=np.asarray(b)\n",
    "        print(b.shape)\n",
    "        b=b.reshape((n,1))\n",
    "        return b\n",
    "\n",
    "class reader_processer:\n",
    "\n",
    "    def read_process_wine(name1,is_drop):\n",
    "        data = pd.read_csv('winequality-red.csv', ';')\n",
    "        data['quality'] = np.where(data['quality'] > 5, 1, 0)\n",
    "        if is_drop:\n",
    "            for s in name1:\n",
    "                data=data.drop(s,axis=1)\n",
    "        wine_data_shuffle = help_method.shuffle(data)\n",
    "        return wine_data_shuffle\n",
    "\n",
    "    def read_process_cancer(name1,is_drop):\n",
    "        data = pd.read_csv('breast-cancer-wisconsin.data', ',',names=[\"ID number\", \"Clump Thickness\", \"Uniformity of cell size\",\"Uniformity of cell shape\",\"Marginal adhesion\", \"Single epithelial cell size\", \"Bare nuclei\", \"Bland chromatin\",\"Normal nucleoli\", \"Mitoses\", \"Class\"])\n",
    "        data = data[(data.astype(str) != '?').all(axis=1)]\n",
    "        data['Bare nuclei']=pd.to_numeric(data['Bare nuclei'])\n",
    "        data = data.drop('ID number', axis=1)\n",
    "        data['Class'] = np.where(data['Class'] > 3, 1, 0)\n",
    "\n",
    "        if is_drop:\n",
    "            for s in name1:\n",
    "                data=data.drop(s,axis=1)\n",
    "\n",
    "        cancer_data_shuffle = help_method.shuffle(data)\n",
    "        return cancer_data_shuffle\n",
    "\n",
    "class experiment:\n",
    "\n",
    "    def wine_experiment_logistic(drop_feature,is_drop,ratio,iter,a,use_reg):\n",
    "        wine_data_shuffle = reader_processer.read_process_wine(drop_feature,is_drop)\n",
    "        help_method.dummy_insert(wine_data_shuffle)\n",
    "        train_x, train_y, test_x, test_y = help_method.train_test_x_y(wine_data_shuffle, ratio,'quality')\n",
    "        w = help_method.random_parameter_generator(train_x.shape[1])\n",
    "        for i in a:\n",
    "            model = logistic_reg(train_x, train_y, test_x, test_y, w)\n",
    "            model.fit(iter, i, use_reg)\n",
    "            print(\"Study Rate at\", i)\n",
    "            folds_x, folds_y = model.validationSets(5)\n",
    "            model.crossValidation(folds_x, folds_y, iter, i, w,use_reg)\n",
    "            print(\"Logistic Accurancy:\",model.evaluate_acc())\n",
    "\n",
    "    def cancer_experiment_logistic(drop_feature,is_drop,ratio,iter,a,use_reg):\n",
    "        cancer_data_shuffle = reader_processer.read_process_cancer(drop_feature,is_drop)\n",
    "        help_method.dummy_insert(cancer_data_shuffle)\n",
    "        train_x, train_y, test_x, test_y = help_method.train_test_x_y(cancer_data_shuffle, ratio, 'Class')\n",
    "        w = help_method.random_parameter_generator(train_x.shape[1])\n",
    "\n",
    "        for i in a:\n",
    "            model = logistic_reg(train_x, train_y, test_x, test_y, w)\n",
    "            model.fit(iter, i, use_reg)\n",
    "            folds_x, folds_y = model.validationSets(5)\n",
    "            print(\"Study Rate at\", i)\n",
    "            model.crossValidation(folds_x, folds_y, iter, i, w,use_reg)\n",
    "            print(\"Logistic Accurancy:\", model.evaluate_acc())\n",
    "            model.confusion_matrix()\n",
    "\n",
    "    def wine_experiment_LDA(drop_feature,is_drop,ratio):\n",
    "        wine_data_shuffle = reader_processer.read_process_wine(drop_feature,is_drop)\n",
    "        train_x, train_y, test_x, test_y = help_method.train_test_x_y(wine_data_shuffle, ratio, 'quality')\n",
    "\n",
    "        lda = lda_model()\n",
    "        lda.fit(train_x, train_y)\n",
    "        folds_x, folds_y = lda.validationSets(5, train_x, train_y)\n",
    "        lda.crossValidation(folds_x, folds_y)\n",
    "        print(\"LDA accurancy\", lda.evaluate_acc(test_y, lda.predict(test_x)))\n",
    "        lda.confusion_matrix(test_x,test_y)\n",
    "\n",
    "    def cancer_experiment_LDA(drop_feature,is_drop,ratio):\n",
    "        cancer_data_shuffle = reader_processer.read_process_cancer(drop_feature,is_drop)\n",
    "        train_x, train_y, test_x, test_y = help_method.train_test_x_y(cancer_data_shuffle, ratio, 'Class')\n",
    "\n",
    "        lda = lda_model()\n",
    "        lda.fit(train_x, train_y)\n",
    "        folds_x, folds_y = lda.validationSets(5,train_x,train_y)\n",
    "        lda.crossValidation(folds_x, folds_y)\n",
    "        print(\"LDA accurancy\", lda.evaluate_acc(test_y, lda.predict(test_x)))\n",
    "        lda.confusion_matrix(test_x,test_y)\n",
    "\n",
    "\n",
    "def main():#the experiments are performed by change the parameters of the following experiment methods\n",
    "    \n",
    "    name1 = [\"pH\", \"residual sugar\", \"free sulfur dioxide\", \"fixed acidity\"]#name of the features to be dropped in the experiments, in this case, it is for the wine data set\n",
    "    ratio = 0.1 #the ratio between the testing set and the whole data set \n",
    "    iter = 100 #the number of gradient descent iterations\n",
    "    use_reg = [False, 0] #whether or not use regularization, value of lambda\n",
    "    a = [ 0.000001, 0.00001, 0.0001, 0.001] #the four learning rate for experiments\n",
    "    print(\"Wine set experiment\")\n",
    "    experiment.wine_experiment_LDA(name1,False,ratio)#the second parameter is whether or not to drop the features in list name1\n",
    "    print(\"-----------------\\n\")\n",
    "    experiment.wine_experiment_logistic(name1,False,ratio,iter,a,use_reg)#the second parameter is whether or not to drop the features in list name1\n",
    "    print(\"\\nCancer set experiment\")\n",
    "    experiment.cancer_experiment_LDA([],False,ratio)#the second parameter is whether or not to drop the features in list name1\n",
    "    print(\"-----------------\\n\")\n",
    "    experiment.cancer_experiment_logistic([],False,ratio,iter,a,use_reg)#the second parameter is whether or not to drop the features in list name1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
